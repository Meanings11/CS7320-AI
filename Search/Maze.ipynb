{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search: Solving a maze\n",
    "\n",
    "Total Points: 10\n",
    "\n",
    "\n",
    "The agent has a map of the maze it is in (i.e., the environment is deterministic, discrete, and known). The agent must use the map to plan a path through the maze from the starting location $S$ to the goal location $G$.  \n",
    "\n",
    "Here is the small example maze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "X                                  SX\n",
      "X            X                      X\n",
      "X            X                      X\n",
      "X            X                      X\n",
      "X            X                      X\n",
      "X            X                      X\n",
      "X            X      X               X\n",
      "X            X      X               X\n",
      "X            X      X               X\n",
      "X            X      X               X\n",
      "X            X      X               X\n",
      "X            X      X               X\n",
      "X            X      X               X\n",
      "XXXXXXXXXXXXXX      XXXXXXXXXXXXXXXXX\n",
      "X            X                      X\n",
      "X            X                      X\n",
      "X            X                      X\n",
      "X                                   X\n",
      "X                                   X\n",
      "X                                   X\n",
      "XG                                  X\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"open_maze.txt\", \"r\")\n",
    "maze_str = f.read()\n",
    "print(maze_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notes:__ \n",
    "* This is a planing exercise, so you do not need to implement an environment, just use the map to search for a path. Once the plan is made, the agent can just follow the path and does not need percepts. The execution phase is trivial and we do not implement it in this exercise.\n",
    "* Tree search algorithm implementations that you find online have often a different aim. The algorithms assume that you already have a tree and the goal is to traverse all nodes. We are interested in dynamically creating a search tree with the aim of finding a good/the best path to the goal state. Ideally, we would like to search only a small part of the maze, i.e., create a search tree with as few nodes as possible. \n",
    "* Some mazes may contain cycles and therefore not form proper trees unless cycles are prevented. \n",
    "\n",
    "## Parsing and pretty printing the maze\n",
    "\n",
    "The maze can also be displayed in color using code in the file [maze_helper.py](maze_helper.py). The code parses the string representing the maze and converts it into a `numpy` 2d array which you can use in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position(0,0): X\n",
      "Position(0,0):  \n",
      "Position(8,1):  \n"
     ]
    }
   ],
   "source": [
    "%run maze_helper.py\n",
    "\n",
    "maze = parse_maze(maze_str)\n",
    "\n",
    "# look at two positions in the maze\n",
    "print(\"Position(0,0):\", maze[0, 0])\n",
    "print(\"Position(0,0):\", maze[8, 1])\n",
    "\n",
    "\n",
    "# there is also a helper function called `look(maze, pos)`\n",
    "print(\"Position(8,1):\", look(maze, [8, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_maze(maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the position of the start and the goal using the helper function `find_pos()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start location: [1, 35]\n",
      "Goal location: [21, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Start location:\", find_pos(maze, what = \"S\"))\n",
    "print(\"Goal location:\", find_pos(maze, what = \"G\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree structures\n",
    "\n",
    "A basic tree implementation in Python is available at https://github.com/yoyzhou/pyTree (found by John Park).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "Implement the following search algorithms for solving different mazes:\n",
    "\n",
    "* Breadth-first search (BFS)\n",
    "* Depth-first search (DFS)\n",
    "* Iterative deepening search (IDS)\n",
    "* Greedy best-first search (GBFS)\n",
    "* A* search\n",
    "\n",
    "Run each of the above algorithms on the \n",
    "[small maze](small_maze.txt), \n",
    "[medium maze](medium_maze.txt), \n",
    "[large maze](large_maze.txt), \n",
    "[open maze](open_maze.txt),\n",
    "[empty maze](empty_maze.txt), \n",
    "[wall maze](wall_maze.txt), \n",
    "and the \n",
    "[loops maze](loops_maze.txt). \n",
    "For each problem instance and each search algorithm, report the following in a table:\n",
    "\n",
    "* The solution and its path cost\n",
    "* Number of nodes expanded\n",
    "* Maximum tree depth searched\n",
    "* Maximum size of the frontier.\n",
    "\n",
    "Display each solution by marking every maze square (or state) visited and the squares on the final path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the search Problem [1 point]\n",
    "\n",
    "Define the components of the search problem:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model\n",
    "* Goal state\n",
    "* Path cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initial state: Point S\n",
    "* Actions: move from one point to another in the maze\n",
    "* Transition model: If it move from one position to another, it ends up in the later location\n",
    "    \n",
    "* Goal state: Point G\n",
    "* Path cost: number of points traversed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Breadth-first, Depth-first and iterative deepening search [4 points]\n",
    "\n",
    "Implement these search strategies. You can implement a generic tree search following the BFS pseudo-code in your textbook and then just adapt the order in which the frontier is explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyTree.Tree import Tree as Tree\n",
    "import random\n",
    "\n",
    "def manhattan(curr, goal):\n",
    "    x_diff = abs(goal[0]-curr[0])\n",
    "    y_diff = abs(goal[1]-curr[1])\n",
    "    \n",
    "    return (x_diff + y_diff)\n",
    "\n",
    "def getDepth(node):\n",
    "    return len(getPath(node))-1\n",
    "\n",
    "def expand(maze, pos):\n",
    "    near_pos = [[pos[0],pos[1]+1],\n",
    "                [pos[0],pos[1]-1],\n",
    "                [pos[0]+1,pos[1]],\n",
    "               [pos[0]-1,pos[1]]]\n",
    "    \n",
    "    random.shuffle(near_pos) #   add stochastic to DFS\n",
    "    \n",
    "    return([next_pos for next_pos in near_pos if look(maze, next_pos) != \"X\"])\n",
    "\n",
    "\n",
    "def getPath(node):\n",
    "    path = []\n",
    "    path.append(node.data)\n",
    "    \n",
    "    # traverse backward\n",
    "    while not node.isRoot():\n",
    "        node = node.getParent()\n",
    "        path.append(node.data)        \n",
    "#         path.reverse()\n",
    "        \n",
    "    return(path)\n",
    "\n",
    "def showPath(maze, path, reached):\n",
    "    maze_temp = np.copy(maze)\n",
    "   \n",
    "    for [x,y] in path:\n",
    "        if maze_temp[x,y] == \" \":\n",
    "            maze_temp[x,y] = \"P\" \n",
    "        \n",
    "    for [x,y] in reached:\n",
    "        if maze_temp[x,y] == \" \":\n",
    "            maze_temp[x,y] = \".\"\n",
    "    \n",
    "    show_maze(maze_temp)\n",
    "    \n",
    "\n",
    "expand(maze,find_pos(maze, what = \"S\"))\n",
    "expand(maze,[3,6])\n",
    "manhattan([8,5], find_pos(maze, what = \"G\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mazeSolver(maze,mode):\n",
    "    if mode == \"IDS\":\n",
    "        # set max depth to 10000\n",
    "        for limit in range(10000):\n",
    "            result = treeSearch(maze,mode,limit, show=False)\n",
    "            if not result == None:\n",
    "                return result\n",
    "        return(None) #fail\n",
    "    else:\n",
    "        return(treeSearch(maze,mode))\n",
    "\n",
    "def treeSearch(maze, mode= \"BFS\", limit=0, debug = False, show = False):\n",
    "    # build the root of the tree\n",
    "    start = find_pos(maze, what = \"S\")\n",
    "    goal = find_pos(maze, what = \"G\")\n",
    "    root = Tree(data = start)\n",
    "    node = root\n",
    "    output = None\n",
    "    \n",
    "    # check show maze flag\n",
    "    if show: maze_vis = np.copy(maze)\n",
    "    \n",
    "    #init frontier and reached\n",
    "    frontier = []\n",
    "    reached = []\n",
    "    frontier.append(root)\n",
    "    reached.append(root.data)\n",
    "    \n",
    "    while not len(frontier) == 0:\n",
    "        # choose the search strategy\n",
    "        if mode == \"BFS\":\n",
    "            node = frontier.pop(0)\n",
    "        elif mode == \"DFS\" or \"IDS\":\n",
    "            node = frontier.pop()\n",
    "        elif mode == \"GRE\": \n",
    "            dis = [manhattan(n.data,goal) for n in frontier]\n",
    "            shortest = dis.index(min(dis))\n",
    "            if debug: print(shortest)\n",
    "            node = frontier.pop(shortest)\n",
    "        elif mode == \"AST\":\n",
    "            # g(n) + h(n)\n",
    "            dis = [len(getPath(n))+manhattan(n.data,goal) for n in frontier]\n",
    "            shortest = dis.index(min(dis))\n",
    "            if debug: print(shortest)\n",
    "            node = frontier.pop(shortest)\n",
    "            \n",
    "        # check if goal\n",
    "        if look(maze, node.data) == \"G\": \n",
    "            return ({\"path\": getPath(node),\n",
    "                     \"reached\": reached,\n",
    "                     \"max_depth\": getDepth(node)})\n",
    "        \n",
    "        if debug: print(getDepth(node))\n",
    "        if debug: root.prettyTree()\n",
    "            \n",
    "        # check if surpass limit\n",
    "        if mode == \"IDS\":\n",
    "            if debug: print(node.data)\n",
    "            if getDepth(node) > limit:\n",
    "                if debug:print(\"PASS\")\n",
    "                continue\n",
    "        \n",
    "        for pos in expand(maze,node.data):\n",
    "    #           DFS check cycle\n",
    "            if not pos in reached:\n",
    "                new_node = Tree(data = pos)\n",
    "                node.addChild(new_node)\n",
    "                frontier.append(new_node)\n",
    "                reached.append(pos)\n",
    "                if show: maze_vis[pos[0], pos[1]] = \".\"\n",
    "        \n",
    "        if show: show_maze(maze_vis)\n",
    "\n",
    "    return(None) #fail\n",
    " \n",
    "# output = treeSearch(maze,mode=\"BFS\",debug = False, show = False)\n",
    "output = mazeSolver(maze,mode=\"IDS\")\n",
    "showPath(maze, output[\"path\"], output[\"reached\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are your implementations complete and optimal? Explain why. What is the time and space complexity of each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Greedy best-first search [2 points]\n",
    "\n",
    "You can use the map to estimate the distance from your current position to the goal using the Manhattan distance (see https://en.wikipedia.org/wiki/Taxicab_geometry) as a heuristic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this implementation complete and optimal? What is the time and space complexity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: A* Search [3 points]\n",
    "\n",
    "Use again the Manhattan heuristic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this implementation complete and optimal? What is the time and space complexity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to add a table that compares the following for the algorithms on the different mazes:\n",
    "\n",
    "* The solution and its path cost\n",
    "* Number of nodes expanded\n",
    "* Maximum tree depth searched\n",
    "* Maximum size of the frontier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Tasks [+1 point]\n",
    "\n",
    "Instead of defining each square as a state (which you probably did), use only intersections as states. Now the storage requirement is reduced, but the path length between two intersections can be different. If we use total path length in number of squares as path cost, how can we make sure that BFS and iterative deepening search is optimal? Change the code to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify your A* search to add weights (see text book) and explore how different weights influence the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if the agent does not know the layout of the maze in advance (i.e., faces an unkown, only partially observable environment)? How does the environment look then (PEAS description)? How would you implement a rational agent to solve the maze? What if the agent still has a GPS device to tell the distance to the goal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/answer goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
